{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c27f3d7",
   "metadata": {},
   "source": [
    "# Introduction to Singular-Value Decomposition (SVD) for Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445f5416",
   "metadata": {},
   "source": [
    "1. Singular-Value Decomposition.\n",
    "2. Calculate Singular-Value Decomposition.\n",
    "3. Reconstruct Matrix from SVD.\n",
    "    * When the original matrix is rectangular.\n",
    "    * When the original matrix is square.\n",
    "4. Using SVD for Pseudoinverse.\n",
    "    * Using pinv method from NumPy.\n",
    "    * Pseudoinverse from scratch via SVD.\n",
    "5. Using SVD for Dimensionality Reduction.\n",
    "    * Dimensionality reduction from scratch with SVD.\n",
    "    * Using TruncatedSVD from scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fecc986",
   "metadata": {},
   "source": [
    "* Perhaps the most known and widely used matrix decomposition method is the **Singular-Value Decomposition, or SVD**.\n",
    "* **All matrices have an SVD, which makes it more stable than other methods, such as the eigendecomposition**. As such, it is often used in a wide array of applications including **compressing, denoising, and data reduction**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe36675d",
   "metadata": {},
   "source": [
    "## 1. Singular-Value Decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aa9176",
   "metadata": {},
   "source": [
    "The Singular-Value Decomposition, or SVD for short, is a matrix decomposition method for reducing a matrix to its constituent parts in order to make certain subsequent matrix calculations simpler.\n",
    "\n",
    "A = U . Sigma . V^T\n",
    "\n",
    "* A is the real m x n matrix that we wish to decompose.\n",
    "* U is an m x m matrix.\n",
    "* Sigma (often represented by the uppercase Greek letter Sigma) is an m x n diagonal matrix.\n",
    "* V^T is the transpose of an n x n matrix where T is a superscript."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656fb4ca",
   "metadata": {},
   "source": [
    "* The diagonal values in the Sigma matrix are known as the **singular values** of the original matrix A.\n",
    "* The columns of the U matrix are called the **left-singular vectors** of A.\n",
    "* The columns of V are called the **right-singular vectors** of A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0756db2a",
   "metadata": {},
   "source": [
    "* *The singular value decomposition (SVD) provides another way to factorize a matrix, into singular vectors and singular values. The SVD allows us to discover some of the same kind of information as the eigendecomposition. However, the SVD is more generally applicable.*\n",
    "* The SVD is used widely both in the calculation of other matrix operations, such as matrix inverse, but also as a **data reduction method in machine learning**.\n",
    "* SVD can also be used in **least squares linear regression, image compression, and denoising data**.\n",
    "* *The singular value decomposition (SVD) has numerous applications in **statistics, machine learning, and computer science**. Applying the SVD to a matrix is like looking inside it with X-ray vision…*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e525097e",
   "metadata": {},
   "source": [
    "## 2. Calculate Singular-Value Decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4afcb9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.2298477   0.88346102  0.40824829]\n",
      " [-0.52474482  0.24078249 -0.81649658]\n",
      " [-0.81964194 -0.40189603  0.40824829]]\n",
      "[9.52551809 0.51430058]\n",
      "[[-0.61962948 -0.78489445]\n",
      " [-0.78489445  0.61962948]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from scipy.linalg import svd\n",
    "\n",
    "A = array([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "U, s, VT = svd(A)\n",
    "print(U)\n",
    "print(s)\n",
    "print(VT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf196b3",
   "metadata": {},
   "source": [
    "## 3. Reconstruct Matrix from SVD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1318e0a9",
   "metadata": {},
   "source": [
    "### When the original matrix is rectangular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d729be37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.52551809 0.        ]\n",
      " [0.         0.51430058]\n",
      " [0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import diag\n",
    "from numpy import dot\n",
    "from numpy import zeros\n",
    "\n",
    "A = array([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "# Apply SVD\n",
    "U, s, VT = svd(A)\n",
    "\n",
    "# create m x n Sigma matrix\n",
    "Sigma = zeros((A.shape[0], A.shape[1]))\n",
    "\n",
    "# populate Sigma with n x n diagonal matrix\n",
    "Sigma[:A.shape[1], :A.shape[1]] = diag(s)\n",
    "print(Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04678c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [3. 4.]\n",
      " [5. 6.]]\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n"
     ]
    }
   ],
   "source": [
    "# reconstruct original matrix\n",
    "B = U.dot(Sigma.dot(VT))\n",
    "print(B)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ad916a",
   "metadata": {},
   "source": [
    "### When the original matrix is square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ccf051b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.68481034e+01 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 1.06836951e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.33475287e-16]]\n"
     ]
    }
   ],
   "source": [
    "A = array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# Apply SVD\n",
    "U, s, VT = svd(A)\n",
    "\n",
    "# create n x n Sigma matrix\n",
    "Sigma = diag(s)\n",
    "print(Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed9819a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "# reconstruct original matrix\n",
    "B = U.dot(Sigma.dot(VT))\n",
    "print(B)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aeeae7",
   "metadata": {},
   "source": [
    "## 4. Using SVD for Pseudoinverse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf71de4",
   "metadata": {},
   "source": [
    "* The pseudoinverse is the generalization of the matrix inverse for square matrices to rectangular matrices where the number of rows and columns are not equal.\n",
    "* It is also called the **Moore-Penrose Inverse** after two independent discoverers of the method or the **Generalized Inverse**.\n",
    "* *Matrix inversion is not defined for matrices that are not square. […] When A has more columns than rows, then solving a linear equation using the pseudoinverse provides one of the many possible solutions.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb3eebf",
   "metadata": {},
   "source": [
    "The pseudoinverse is denoted as **A^+**, where A is the matrix that is being inverted and + is a superscript. The pseudoinverse is calculated using the singular value decomposition of A:\n",
    "\n",
    "A^+ = V . D^+ . U^T\n",
    "\n",
    "* A^+ is the pseudoinverse.\n",
    "* D^+ is the pseudoinverse of the diagonal matrix Sigma.\n",
    "* U^T is the transpose of U."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a5b4ae",
   "metadata": {},
   "source": [
    "We can get U and V from the SVD operation:\n",
    "\n",
    "A = U . Sigma . V^T\n",
    "\n",
    "The D^+ can be calculated by creating a diagonal matrix from Sigma, **calculating the reciprocal of each non-zero element in Sigma**, and taking the transpose **if the original matrix was rectangular**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edd7261",
   "metadata": {},
   "source": [
    "The pseudoinverse provides one way of solving the **linear regression equation**, specifically when there are more rows than there are columns, which is often the case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b4d94d",
   "metadata": {},
   "source": [
    "### Using pinv method from NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5521f622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1 0.2]\n",
      " [0.3 0.4]\n",
      " [0.5 0.6]\n",
      " [0.7 0.8]]\n",
      "[[-1.00000000e+01 -5.00000000e+00  9.07607323e-15  5.00000000e+00]\n",
      " [ 8.50000000e+00  4.50000000e+00  5.00000000e-01 -3.50000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "from numpy.linalg import pinv\n",
    "\n",
    "A = array([\n",
    "    [0.1, 0.2],\n",
    "    [0.3, 0.4],\n",
    "    [0.5, 0.6],\n",
    "    [0.7, 0.8]])\n",
    "print(A)\n",
    "\n",
    "B = pinv(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd5efca",
   "metadata": {},
   "source": [
    "### Pseudoinverse from scratch via SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9fcc063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1 0.2]\n",
      " [0.3 0.4]\n",
      " [0.5 0.6]\n",
      " [0.7 0.8]]\n",
      "[[-1.00000000e+01 -5.00000000e+00  9.07607323e-15  5.00000000e+00]\n",
      " [ 8.50000000e+00  4.50000000e+00  5.00000000e-01 -3.50000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "A = array([\n",
    "    [0.1, 0.2],\n",
    "    [0.3, 0.4],\n",
    "    [0.5, 0.6],\n",
    "    [0.7, 0.8]])\n",
    "\n",
    "# calculate svd\n",
    "U, s, VT = svd(A)\n",
    "\n",
    "# reciprocals of s\n",
    "d = 1.0 / s\n",
    "\n",
    "# create m x n D matrix\n",
    "D = zeros(A.shape)\n",
    "\n",
    "# populate D with n x n diagonal matrix\n",
    "D[:A.shape[1], :A.shape[1]] = diag(d)\n",
    "\n",
    "# calculate pseudoinverse\n",
    "B = VT.T.dot(D.T).dot(U.T)\n",
    "\n",
    "print(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e180162",
   "metadata": {},
   "source": [
    "## 5. Using SVD for Dimensionality Reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c368c0e9",
   "metadata": {},
   "source": [
    "* Data with a large number of features, such as **more features (columns) than observations (rows)** may be reduced to a smaller subset of features that are most relevant to the prediction problem. The result is **a matrix with a lower rank** that is said to approximate the original matrix.\n",
    "* To do this we can perform an SVD operation on the original data and **select the top k largest singular values** in Sigma. These columns can be selected from Sigma and the rows selected from V^T."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff77180",
   "metadata": {},
   "source": [
    "* An approximate B of the original vector A can then be reconstructed:\n",
    "\n",
    "    B = U . Sigmak . V^Tk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a440ba2a",
   "metadata": {},
   "source": [
    "* In **natural language processing**, this approach can be used on matrices of **word occurrences or word frequencies** in documents and is called **Latent Semantic Analysis or Latent Semantic Indexing**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b64e36e",
   "metadata": {},
   "source": [
    "* In practice, we can retain and work with a descriptive subset of the data called T. This is a dense summary of the matrix or a projection:\n",
    "\n",
    "    T = U . Sigmak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abc9584",
   "metadata": {},
   "source": [
    "* Further, this transform can be calculated and applied to the original matrix A as well as other similar matrices:\n",
    "\n",
    "    T = V^k . A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c12e92c",
   "metadata": {},
   "source": [
    "### Dimensionality reduction from scratch with SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5a6e5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4  5  6  7  8  9 10]\n",
      " [11 12 13 14 15 16 17 18 19 20]\n",
      " [21 22 23 24 25 26 27 28 29 30]]\n"
     ]
    }
   ],
   "source": [
    "A = array([\n",
    "    [1,2,3,4,5,6,7,8,9,10],\n",
    "    [11,12,13,14,15,16,17,18,19,20],\n",
    "    [21,22,23,24,25,26,27,28,29,30]\n",
    "])\n",
    "\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0d20cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "(3,)\n",
      "(10, 10)\n"
     ]
    }
   ],
   "source": [
    "# Singular-value decomposition\n",
    "U, s, VT = svd(A)\n",
    "print(U.shape)\n",
    "print(s.shape)\n",
    "print(VT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "697ae750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 10)\n",
      "[[9.69657342e+01 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 7.25578339e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 1.48879510e-15 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# create m x n Sigma matrix\n",
    "Sigma = zeros((A.shape[0], A.shape[1]))\n",
    "\n",
    "# populate Sigma with n x n diagonal matrix\n",
    "Sigma[:A.shape[0], :A.shape[0]] = diag(s)\n",
    "print(Sigma.shape)\n",
    "print(Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "133e3af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[96.96573419  0.        ]\n",
      " [ 0.          7.25578339]\n",
      " [ 0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# select k elements\n",
    "k = 2\n",
    "Sigma = Sigma[:, :k]\n",
    "VT = VT[:k, :]\n",
    "print(Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b238c71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      " [11. 12. 13. 14. 15. 16. 17. 18. 19. 20.]\n",
      " [21. 22. 23. 24. 25. 26. 27. 28. 29. 30.]]\n"
     ]
    }
   ],
   "source": [
    "# reconstruct\n",
    "B = U.dot(Sigma.dot(VT))\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30d86880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-18.52157747  -6.47697214]\n",
      " [-49.81310011  -1.91182038]\n",
      " [-81.10462276   2.65333138]]\n"
     ]
    }
   ],
   "source": [
    "# transform\n",
    "T = U.dot(Sigma)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b85e153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-18.52157747  -6.47697214]\n",
      " [-49.81310011  -1.91182038]\n",
      " [-81.10462276   2.65333138]]\n"
     ]
    }
   ],
   "source": [
    "# another way to transform\n",
    "T = A.dot(VT.T)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a003c9a3",
   "metadata": {},
   "source": [
    "* The scikit-learn provides a **TruncatedSVD** class that implements this capability directly.\n",
    "* The TruncatedSVD class can be created in which you must specify the number of desirable features or components to select, e.g. 2. Once created, you can fit the transform (e.g. calculate V^Tk) by calling the **fit()** function, then apply it to the original matrix by calling the **transform()** function. **The result is the transform of A called T** above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30bf5c7",
   "metadata": {},
   "source": [
    "### Using TruncatedSVD from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7458be00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4  5  6  7  8  9 10]\n",
      " [11 12 13 14 15 16 17 18 19 20]\n",
      " [21 22 23 24 25 26 27 28 29 30]]\n",
      "[[18.52157747  6.47697214]\n",
      " [49.81310011  1.91182038]\n",
      " [81.10462276 -2.65333138]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "A = array([\n",
    "    [1,2,3,4,5,6,7,8,9,10],\n",
    "    [11,12,13,14,15,16,17,18,19,20],\n",
    "    [21,22,23,24,25,26,27,28,29,30]\n",
    "])\n",
    "\n",
    "print(A)\n",
    "\n",
    "# svd\n",
    "svd = TruncatedSVD(n_components=2)\n",
    "svd.fit(A)\n",
    "result = svd.transform(A)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2750ccbc",
   "metadata": {},
   "source": [
    "* We can see that the values match those calculated manually above, **except for the sign on some values**. We can expect there to be some instability when it comes to the sign given the nature of the calculations involved and the differences in the underlying libraries and methods used. This instability of sign should not be a problem in practice as long as the transform is trained for reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a08acce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
